{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====== Nguồn http://users.soict.hust.edu.vn/khoattq/ml-dm-course/ ======\n",
    "\n",
    "\n",
    "\n",
    "## Bài toán\n",
    "Dữ liệu gồm n văn bản phân vào 10 chủ đề khác nhau. Cần biễu diễn mỗi văn bản dưới dạng một vector số thể hiện cho nội dụng của văn bản đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mục lục\n",
    "- Load dữ liệu từ thư mục\n",
    "- Loại bỏ các stop words\n",
    "- Sử dụng thư viện để mã hóa TF-IDF cho mỗi văn bản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phương pháp mã hóa: TF-IDF\n",
    "Cho tập gồm $n$ văn bản: $D = \\{d_1, d_2, ... d_n\\}$. Tập từ điển tương ứng được xây dựng từ $n$ văn bản này có độ dài là $m$\n",
    "- Xét văn bản $d$ có $|d|$ từ và $t$ là một từ trong $d$. Mã hóa tf-idf của $t$ trong văn bản $d$ được biểu diễn:\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\text{tf}_{t, d} &= \\frac{f_t}{|d|} \\\\\n",
    "        \\text{idf}_{t, d} &= \\log\\frac{n}{n_t}, \\ \\ \\ \\ n_t = |\\{d\\in D: t\\in d\\}| \\\\\n",
    "        \\text{tf-idf}_{t d} &= \\text{tf}_{t, d} \\times \\text{idf}_{t, d}\n",
    "    \\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "- Khi đó văn bản $d$ được mã hóa là một vector $m$ chiều. Các từ xuất hiện trong d sẽ được thay bằng giá trị tf-idf tương ứng. Các từ không xuất hiện trong $d$ thì thay là 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dữ liệu từ thư mục\n",
    "\n",
    "Cấu trúc thư mục như sau \n",
    "\n",
    "- data/news_vnexpress/\n",
    "\n",
    "    - Kinh tế: \n",
    "        - bài báo 1.txt \n",
    "        - bài báo 2.txt \n",
    "    - Pháp luật\n",
    "        - bài báo 3.txt \n",
    "        - bài báo 4.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'data/news_vnexpress'\n",
    "os.makedirs(\"images\",exist_ok=True)  # thư mục lưu các các hình ảnh kết quả trong quá trình huấn luyện và đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các nhãn và số văn bản tương ứng trong dữ liệu\n",
      "----------------------------------------------\n",
      "doi-song: 120\n",
      "du-lich: 54\n",
      "giai-tri: 180\n",
      "-------------------------\n",
      "Tổng số văn bản: 354\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "print('Các nhãn và số văn bản tương ứng trong dữ liệu')\n",
    "print('----------------------------------------------')\n",
    "n = 0\n",
    "for label in os.listdir(INPUT):\n",
    "    print(f'{label}: {len(os.listdir(os.path.join(INPUT, label)))}')\n",
    "    n += len(os.listdir(os.path.join(INPUT, label)))\n",
    "\n",
    "print('-------------------------')\n",
    "print(f\"Tổng số văn bản: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping:\n",
      "doi-song - 0\n",
      "du-lich - 1\n",
      "giai-tri - 2\n",
      "--------------------------\n",
      "['data/news_vnexpress\\\\doi-song\\\\00006.txt']\n",
      "[0]\n",
      "['Nhân ngày lễ tình nhân 14/2, Viktoria Pustovitova, 28 tuổi và Alexander Kudlay, 33 tuổi, quyết định xích tay nhau ba tháng để thử thách tình yêu.Sau khi \"chung xích\", đôi tình nhân ở Kharkiv tin rằng họ có thể cùng nhau vượt qua mọi sự bất tiện trong sinh hoạt, từ rửa bát, nấu thức ăn đến đi vệ sinh và lái xe ô tô.Tuy nhiên, hôm 26/2, truyền thông Ukraine đưa tin, sợi xích đã khiến cô Viktoria bị loét cổ tay. \"Chúng tôi đã bôi thuốc nhưng không được. Đó quả là một cơn ác mộng\", cô gái nói.Họ buộc phải đến bệnh viện để xử lý vết thương ở cổ tay.Bác sĩ da liễu Tatyana Egorova cảnh báo, đôi tình nhân có thể phải từ bỏ thử thách tình yêu. \"Đây là vết loét do tiếp xúc lâu với kim loại. Các mô da bị kẹp liên tục nên dẫn đến rối loạn tuần hoàn\", bác sĩ này nói.Viktoria và Alexander có thể làm mọi việc hàng ngày cùng nhau. Tuy nhiên, vào nhà vệ sinh công cộng khiến họ gặp chút rắc rối. Viktoria muốn dùng nhà vệ sinh nữ, nhưng cô bị mọi người tỏ thái độ khó chịu khi đưa cả bạn trai đi cùng.Alexander cho biết thử thách bất thường này là ý tưởng của anh. Bạn gái từng dọn ra ngoài sau \"cuộc cãi vã nhỏ\" nên anh nghĩ ra cách này.\"Tôi nói đùa rằng anh sẽ trói em lại. Cuối cùng thì chúng tôi đã làm như vậy. Lúc đầu Viktoria không đồng ý nhưng tôi đã thuyết phục được cô ấy\".Nhật Minh (Theo LB)\\n']\n",
      "\n",
      "Tổng số  văn bản: 354\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_train = load_files(container_path=INPUT, encoding=\"utf-8\")\n",
    "print('mapping:')\n",
    "for i in range(len(data_train.target_names)):\n",
    "    print(f'{data_train.target_names[i]} - {i}')\n",
    "\n",
    "print('--------------------------')\n",
    "print(data_train.filenames[0:1])\n",
    "# print(data_train.data[0:1])\n",
    "print(data_train.target[0:1])\n",
    "print(data_train.data[0:1])\n",
    "\n",
    "print(\"\\nTổng số  văn bản: {}\" .format( len(data_train.filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển dữ liệu dạng text về ma trận (n x m) bằng TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng stopwords: 2063\n",
      "['a_lô', 'a_ha', 'ai', 'ai_ai', 'ai_nấy', 'ai_đó', 'alô', 'amen', 'anh', 'anh_ấy']\n",
      "\n",
      "Số lượng từ trong từ điển: 6413\n",
      "Kích thước dữ liệu sau khi xử lý: (354, 6413)\n",
      "Kích thước nhãn tương ứng: (354,)\n"
     ]
    }
   ],
   "source": [
    "# load dữ liệu các stopwords \n",
    "with open(\"data/vietnamese-stopwords.txt\", encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip().replace(\" \", \"_\") for x in stopwords] \n",
    "print(f\"Số lượng stopwords: {len(stopwords)}\")\n",
    "print(stopwords[:10])\n",
    "\n",
    "# Chuyển hoá dữ liệu text về dạng vector TF \n",
    "#     - loại bỏ từ dừng\n",
    "#     - sinh từ điển\n",
    "module_count_vector = CountVectorizer(stop_words=stopwords)\n",
    "model_rf_preprocess = Pipeline([('vect', module_count_vector),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ])\n",
    "# Hàm thực hiện chuyển đổi dữ liệu text thành dữ liệu số dạng ma trận \n",
    "# Input: Dữ liệu 2 chiều dạng numpy.array, mảng nhãn id dạng numpy.array \n",
    "data_preprocessed = model_rf_preprocess.fit_transform(data_train.data, data_train.target)\n",
    "\n",
    "print(f\"\\nSố lượng từ trong từ điển: {len(module_count_vector.vocabulary_)}\")\n",
    "print(f\"Kích thước dữ liệu sau khi xử lý: {data_preprocessed.shape}\")\n",
    "print(f\"Kích thước nhãn tương ứng: {data_train.target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_preprocessed\n",
    "Y = data_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354, 6413), (354,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(X[100].toarray())\n",
    "print(Y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(X[100].toarray() != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6384)\t0.18895921086566383\n",
      "  (0, 5791)\t0.3905893510067745\n",
      "  (0, 2451)\t0.5034928675157354\n",
      "  (0, 1708)\t0.6953314500077334\n",
      "  (0, 442)\t0.2733925428757287\n"
     ]
    }
   ],
   "source": [
    "print(X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
